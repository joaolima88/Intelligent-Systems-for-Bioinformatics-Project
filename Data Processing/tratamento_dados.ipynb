{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5fa1ffb",
   "metadata": {},
   "source": [
    "Passo 0 — Imports e carregar o CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab6a7026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12918, 23)\n",
      "['Name', 'Ab or Nb', 'Binds to', \"Doesn't Bind to\", 'Neutralising Vs', 'Not Neutralising Vs', 'Protein + Epitope', 'Origin', 'VHorVHH', 'VL', 'Heavy V Gene', 'Heavy J Gene', 'Light V Gene', 'Light J Gene', 'CDRH3', 'CDRL3', 'Structures', 'ABB Homology Model (if no structure)', 'Sources', 'Date Added', 'Last Updated', 'Update Description', 'Notes/Following Up?']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Ab or Nb</th>\n",
       "      <th>Binds to</th>\n",
       "      <th>Doesn't Bind to</th>\n",
       "      <th>Neutralising Vs</th>\n",
       "      <th>Not Neutralising Vs</th>\n",
       "      <th>Protein + Epitope</th>\n",
       "      <th>Origin</th>\n",
       "      <th>VHorVHH</th>\n",
       "      <th>VL</th>\n",
       "      <th>...</th>\n",
       "      <th>Light J Gene</th>\n",
       "      <th>CDRH3</th>\n",
       "      <th>CDRL3</th>\n",
       "      <th>Structures</th>\n",
       "      <th>ABB Homology Model (if no structure)</th>\n",
       "      <th>Sources</th>\n",
       "      <th>Date Added</th>\n",
       "      <th>Last Updated</th>\n",
       "      <th>Update Description</th>\n",
       "      <th>Notes/Following Up?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Curtis_3548_S-2</td>\n",
       "      <td>Ab</td>\n",
       "      <td>SARS-CoV2_WT;SARS-CoV2_Beta</td>\n",
       "      <td>SARS-CoV2_Omicron-BA1;HKU1</td>\n",
       "      <td>SARS-CoV2_WT (weak)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S; RBD/non-RBD</td>\n",
       "      <td>B-cells; SARS-CoV2 Human Patient</td>\n",
       "      <td>ND</td>\n",
       "      <td>ND</td>\n",
       "      <td>...</td>\n",
       "      <td>ND</td>\n",
       "      <td>ARGSRNDLRDFDY</td>\n",
       "      <td>QSYNSSLSGLVV</td>\n",
       "      <td>ND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nicholas Curtis et al., 2023 (https://www.bior...</td>\n",
       "      <td>Feb 8, 2024</td>\n",
       "      <td>Feb 8, 2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Complete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Curtis_3548_S-7</td>\n",
       "      <td>Ab</td>\n",
       "      <td>SARS-CoV2_WT;SARS-CoV2_Beta</td>\n",
       "      <td>SARS-CoV2_Omicron-BA1;HKU1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SARS-CoV2_WT</td>\n",
       "      <td>S; non-RBD</td>\n",
       "      <td>B-cells; SARS-CoV2 Human Patient</td>\n",
       "      <td>ND</td>\n",
       "      <td>ND</td>\n",
       "      <td>...</td>\n",
       "      <td>ND</td>\n",
       "      <td>AREPYSSGMGGRDY</td>\n",
       "      <td>QQYGSSPYT</td>\n",
       "      <td>ND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nicholas Curtis et al., 2023 (https://www.bior...</td>\n",
       "      <td>Feb 8, 2024</td>\n",
       "      <td>Feb 8, 2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Complete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Curtis_3548_RBD-15</td>\n",
       "      <td>Ab</td>\n",
       "      <td>SARS-CoV2_WT</td>\n",
       "      <td>SARS-CoV2_Beta;SARS-CoV2_Omicron-BA1;HKU1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SARS-CoV2_WT</td>\n",
       "      <td>S; iso-RBD</td>\n",
       "      <td>B-cells; SARS-CoV2 Human Patient</td>\n",
       "      <td>ND</td>\n",
       "      <td>ND</td>\n",
       "      <td>...</td>\n",
       "      <td>ND</td>\n",
       "      <td>AKGIYSSSSYWFGP</td>\n",
       "      <td>QAWDSSTVV</td>\n",
       "      <td>ND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nicholas Curtis et al., 2023 (https://www.bior...</td>\n",
       "      <td>Feb 8, 2024</td>\n",
       "      <td>Feb 8, 2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Binds only non-prefusion stabilised RBD. Complete</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name Ab or Nb                     Binds to  \\\n",
       "0     Curtis_3548_S-2       Ab  SARS-CoV2_WT;SARS-CoV2_Beta   \n",
       "1     Curtis_3548_S-7       Ab  SARS-CoV2_WT;SARS-CoV2_Beta   \n",
       "2  Curtis_3548_RBD-15       Ab                 SARS-CoV2_WT   \n",
       "\n",
       "                             Doesn't Bind to      Neutralising Vs  \\\n",
       "0                 SARS-CoV2_Omicron-BA1;HKU1  SARS-CoV2_WT (weak)   \n",
       "1                 SARS-CoV2_Omicron-BA1;HKU1                  NaN   \n",
       "2  SARS-CoV2_Beta;SARS-CoV2_Omicron-BA1;HKU1                  NaN   \n",
       "\n",
       "  Not Neutralising Vs Protein + Epitope                            Origin  \\\n",
       "0                 NaN    S; RBD/non-RBD  B-cells; SARS-CoV2 Human Patient   \n",
       "1        SARS-CoV2_WT        S; non-RBD  B-cells; SARS-CoV2 Human Patient   \n",
       "2        SARS-CoV2_WT        S; iso-RBD  B-cells; SARS-CoV2 Human Patient   \n",
       "\n",
       "  VHorVHH  VL  ... Light J Gene           CDRH3         CDRL3 Structures  \\\n",
       "0      ND  ND  ...           ND   ARGSRNDLRDFDY  QSYNSSLSGLVV         ND   \n",
       "1      ND  ND  ...           ND  AREPYSSGMGGRDY     QQYGSSPYT         ND   \n",
       "2      ND  ND  ...           ND  AKGIYSSSSYWFGP     QAWDSSTVV         ND   \n",
       "\n",
       "  ABB Homology Model (if no structure)  \\\n",
       "0                                  NaN   \n",
       "1                                  NaN   \n",
       "2                                  NaN   \n",
       "\n",
       "                                             Sources   Date Added  \\\n",
       "0  Nicholas Curtis et al., 2023 (https://www.bior...  Feb 8, 2024   \n",
       "1  Nicholas Curtis et al., 2023 (https://www.bior...  Feb 8, 2024   \n",
       "2  Nicholas Curtis et al., 2023 (https://www.bior...  Feb 8, 2024   \n",
       "\n",
       "   Last Updated Update Description  \\\n",
       "0   Feb 8, 2024                NaN   \n",
       "1   Feb 8, 2024                NaN   \n",
       "2   Feb 8, 2024                NaN   \n",
       "\n",
       "                                 Notes/Following Up?  \n",
       "0                                           Complete  \n",
       "1                                           Complete  \n",
       "2  Binds only non-prefusion stabilised RBD. Complete  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "PATH_CSV = \"CoV-AbDab_080224.csv\"  # ajusta o path se necessário\n",
    "\n",
    "df_raw = pd.read_csv(PATH_CSV)\n",
    "print(df_raw.shape)\n",
    "print(df_raw.columns.tolist())\n",
    "df_raw.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60362910",
   "metadata": {},
   "source": [
    "Passo 1 — Funções utilitárias (parsing de variantes e PDB IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0054eb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "AA_VALID = set(list(\"ACDEFGHIKLMNPQRSTVWY\"))  # 20 AAs padrão\n",
    "\n",
    "def split_multi_field(x: str) -> list[str]:\n",
    "    \"\"\"Divide campos multi-valor; ignora ND/vazios.\"\"\"\n",
    "    if pd.isna(x):\n",
    "        return []\n",
    "    s = str(x).strip()\n",
    "    if s in (\"\", \"ND\", \"nan\"):\n",
    "        return []\n",
    "    parts = re.split(r\"[;,]\\s*\", s)\n",
    "    parts = [p.strip() for p in parts if p.strip() and p.strip() != \"ND\"]\n",
    "    return parts\n",
    "\n",
    "def normalize_variant(v: str) -> str:\n",
    "    \"\"\"Remove ruído tipo '(weak)' e normaliza espaços.\"\"\"\n",
    "    v = str(v)\n",
    "    v = v.replace(\"(weak)\", \"\").replace(\"weak\", \"\")\n",
    "    v = re.sub(r\"\\s+\", \"\", v)\n",
    "    # casos raros do tipo '(weak)SARS-CoV2_...' ou colados\n",
    "    v = v.replace(\")SARS\", \"SARS\")\n",
    "    v = v.strip()\n",
    "    return v\n",
    "\n",
    "def is_sarscov2(v: str) -> bool:\n",
    "    \"\"\"Mantém apenas variantes SARS-CoV-2 (depois de normalizar).\"\"\"\n",
    "    v = normalize_variant(v)\n",
    "    return v.startswith(\"SARS-CoV2\")\n",
    "\n",
    "def extract_pdb_ids(structures_field: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Extrai IDs PDB (4 chars) de:\n",
    "    - 'ND'\n",
    "    - URLs do RCSB: https://www.rcsb.org/structure/7YH6;...\n",
    "    - ou strings que contenham o padrão de PDB id\n",
    "    \"\"\"\n",
    "    if pd.isna(structures_field):\n",
    "        return []\n",
    "    s = str(structures_field)\n",
    "    if s.strip() in (\"\", \"ND\"):\n",
    "        return []\n",
    "    # encontra padrões 4-char típicos de PDB (ex: 7YH6, 8IX3)\n",
    "    # PDB IDs: [0-9][A-Za-z0-9]{3}\n",
    "    ids = re.findall(r\"\\b[0-9][A-Za-z0-9]{3}\\b\", s)\n",
    "    # normaliza para uppercase\n",
    "    ids = [i.upper() for i in ids]\n",
    "    # remove duplicados preservando ordem\n",
    "    seen = set()\n",
    "    out = []\n",
    "    for i in ids:\n",
    "        if i not in seen:\n",
    "            out.append(i)\n",
    "            seen.add(i)\n",
    "    return out\n",
    "\n",
    "def clean_sequence(seq: str) -> str | None:\n",
    "    \"\"\"Remove espaços, troca 'ND' por None e valida se só tem aminoácidos.\"\"\"\n",
    "    if pd.isna(seq):\n",
    "        return None\n",
    "    s = str(seq).strip().upper()\n",
    "    if s in (\"\", \"ND\", \"N/A\", \"NA\"):\n",
    "        return None\n",
    "    s = re.sub(r\"\\s+\", \"\", s)\n",
    "    # valida caracteres\n",
    "    if any(ch not in AA_VALID for ch in s):\n",
    "        return None\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01e9a62",
   "metadata": {},
   "source": [
    "Passo 2 — Selecionar e limpar colunas essenciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d56fff54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antes filtros: (12918, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VHorVHH</th>\n",
       "      <th>VL</th>\n",
       "      <th>Structures</th>\n",
       "      <th>Neutralising Vs</th>\n",
       "      <th>Not Neutralising Vs</th>\n",
       "      <th>chain_heavy</th>\n",
       "      <th>chain_light</th>\n",
       "      <th>pdb_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ND</td>\n",
       "      <td>ND</td>\n",
       "      <td>ND</td>\n",
       "      <td>SARS-CoV2_WT (weak)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ND</td>\n",
       "      <td>ND</td>\n",
       "      <td>ND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SARS-CoV2_WT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ND</td>\n",
       "      <td>ND</td>\n",
       "      <td>ND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SARS-CoV2_WT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  VHorVHH  VL Structures      Neutralising Vs Not Neutralising Vs chain_heavy  \\\n",
       "0      ND  ND         ND  SARS-CoV2_WT (weak)                 NaN        None   \n",
       "1      ND  ND         ND                  NaN        SARS-CoV2_WT        None   \n",
       "2      ND  ND         ND                  NaN        SARS-CoV2_WT        None   \n",
       "\n",
       "  chain_light pdb_ids  \n",
       "0        None      []  \n",
       "1        None      []  \n",
       "2        None      []  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_needed = [\"VHorVHH\", \"VL\", \"Structures\", \"Neutralising Vs\", \"Not Neutralising Vs\"]\n",
    "missing = [c for c in cols_needed if c not in df_raw.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Faltam colunas esperadas: {missing}\")\n",
    "\n",
    "df = df_raw[cols_needed].copy()\n",
    "\n",
    "# limpar sequências\n",
    "df[\"chain_heavy\"] = df[\"VHorVHH\"].apply(clean_sequence)\n",
    "df[\"chain_light\"] = df[\"VL\"].apply(clean_sequence)\n",
    "\n",
    "# extrair PDBs\n",
    "df[\"pdb_ids\"] = df[\"Structures\"].apply(extract_pdb_ids)\n",
    "\n",
    "print(\"Antes filtros:\", df.shape)\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae2f7a7",
   "metadata": {},
   "source": [
    "Passo 3 — Filtrar: apenas entradas com VH + VL + pelo menos 1 PDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9684151e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depois filtros VH+VL+PDB: (576, 8)\n"
     ]
    }
   ],
   "source": [
    "df_f = df.dropna(subset=[\"chain_heavy\", \"chain_light\"]).copy()\n",
    "df_f = df_f[df_f[\"pdb_ids\"].map(len) > 0].copy()\n",
    "\n",
    "print(\"Depois filtros VH+VL+PDB:\", df_f.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48209a91",
   "metadata": {},
   "source": [
    "Passo 4 — Expandir para o formato “1 interação por linha”\n",
    "\n",
    "Aqui criamos:\n",
    "\n",
    "linhas positivas (label=1) para cada variante em Neutralising Vs\n",
    "\n",
    "linhas negativas (label=0) para cada variante em Not Neutralising Vs\n",
    "\n",
    "E mantemos só SARS-CoV-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "421c2e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interações (antes dedup): (4196, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdb_id</th>\n",
       "      <th>chain_heavy</th>\n",
       "      <th>chain_light</th>\n",
       "      <th>variant_target</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8J1T</td>\n",
       "      <td>VQLVESGGGLVQPGGSLRLSCAASGLTVSSNYMNWVRQAPGKGLEW...</td>\n",
       "      <td>DIQMTQSPSFLSASVGDRVTITCRASQGISSYLAWYQQKPGKAPKL...</td>\n",
       "      <td>SARS-CoV2_WT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8J1T</td>\n",
       "      <td>VQLVESGGGLVQPGGSLRLSCAASGLTVSSNYMNWVRQAPGKGLEW...</td>\n",
       "      <td>DIQMTQSPSFLSASVGDRVTITCRASQGISSYLAWYQQKPGKAPKL...</td>\n",
       "      <td>SARS-CoV2_Alpha</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8J1T</td>\n",
       "      <td>VQLVESGGGLVQPGGSLRLSCAASGLTVSSNYMNWVRQAPGKGLEW...</td>\n",
       "      <td>DIQMTQSPSFLSASVGDRVTITCRASQGISSYLAWYQQKPGKAPKL...</td>\n",
       "      <td>SARS-CoV2_Beta</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8J1T</td>\n",
       "      <td>VQLVESGGGLVQPGGSLRLSCAASGLTVSSNYMNWVRQAPGKGLEW...</td>\n",
       "      <td>DIQMTQSPSFLSASVGDRVTITCRASQGISSYLAWYQQKPGKAPKL...</td>\n",
       "      <td>SARS-CoV2_Gamma</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8J1T</td>\n",
       "      <td>VQLVESGGGLVQPGGSLRLSCAASGLTVSSNYMNWVRQAPGKGLEW...</td>\n",
       "      <td>DIQMTQSPSFLSASVGDRVTITCRASQGISSYLAWYQQKPGKAPKL...</td>\n",
       "      <td>SARS-CoV2_Delta</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pdb_id                                        chain_heavy  \\\n",
       "0   8J1T  VQLVESGGGLVQPGGSLRLSCAASGLTVSSNYMNWVRQAPGKGLEW...   \n",
       "1   8J1T  VQLVESGGGLVQPGGSLRLSCAASGLTVSSNYMNWVRQAPGKGLEW...   \n",
       "2   8J1T  VQLVESGGGLVQPGGSLRLSCAASGLTVSSNYMNWVRQAPGKGLEW...   \n",
       "3   8J1T  VQLVESGGGLVQPGGSLRLSCAASGLTVSSNYMNWVRQAPGKGLEW...   \n",
       "4   8J1T  VQLVESGGGLVQPGGSLRLSCAASGLTVSSNYMNWVRQAPGKGLEW...   \n",
       "\n",
       "                                         chain_light   variant_target  label  \n",
       "0  DIQMTQSPSFLSASVGDRVTITCRASQGISSYLAWYQQKPGKAPKL...     SARS-CoV2_WT      1  \n",
       "1  DIQMTQSPSFLSASVGDRVTITCRASQGISSYLAWYQQKPGKAPKL...  SARS-CoV2_Alpha      1  \n",
       "2  DIQMTQSPSFLSASVGDRVTITCRASQGISSYLAWYQQKPGKAPKL...   SARS-CoV2_Beta      1  \n",
       "3  DIQMTQSPSFLSASVGDRVTITCRASQGISSYLAWYQQKPGKAPKL...  SARS-CoV2_Gamma      1  \n",
       "4  DIQMTQSPSFLSASVGDRVTITCRASQGISSYLAWYQQKPGKAPKL...  SARS-CoV2_Delta      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = []\n",
    "\n",
    "for _, row in df_f.iterrows():\n",
    "    vh = row[\"chain_heavy\"]\n",
    "    vl = row[\"chain_light\"]\n",
    "    pdb_list = row[\"pdb_ids\"]\n",
    "\n",
    "    pos_vars = [normalize_variant(v) for v in split_multi_field(row[\"Neutralising Vs\"]) if is_sarscov2(v)]\n",
    "    neg_vars = [normalize_variant(v) for v in split_multi_field(row[\"Not Neutralising Vs\"]) if is_sarscov2(v)]\n",
    "\n",
    "    # Se a mesma variante aparecer como pos e neg, é ambíguo -> removemos essa variante\n",
    "    pos_set = set(pos_vars)\n",
    "    neg_set = set(neg_vars)\n",
    "    conflicts = pos_set & neg_set\n",
    "    if conflicts:\n",
    "        pos_vars = [v for v in pos_vars if v not in conflicts]\n",
    "        neg_vars = [v for v in neg_vars if v not in conflicts]\n",
    "\n",
    "    # Estratégia simples: usar o 1º PDB como representante do anticorpo\n",
    "    # (Se quiseres, depois fazemos versão \"explode PDBs\" também.)\n",
    "    pdb_id = pdb_list[0]\n",
    "\n",
    "    for v in pos_vars:\n",
    "        records.append((pdb_id, vh, vl, v, 1))\n",
    "\n",
    "    for v in neg_vars:\n",
    "        records.append((pdb_id, vh, vl, v, 0))\n",
    "\n",
    "df_pairs = pd.DataFrame(records, columns=[\"pdb_id\", \"chain_heavy\", \"chain_light\", \"variant_target\", \"label\"])\n",
    "print(\"Interações (antes dedup):\", df_pairs.shape)\n",
    "df_pairs.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18848f3",
   "metadata": {},
   "source": [
    "Passo 5 — Remover duplicados e validar labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c5867f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interações (depois dedup): (3994, 5)\n",
      "PDBs únicos: 472\n",
      "label\n",
      "1    0.639209\n",
      "0    0.360791\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_pairs = df_pairs.drop_duplicates(subset=[\"pdb_id\", \"variant_target\", \"label\"]).copy()\n",
    "\n",
    "# sanity checks\n",
    "assert set(df_pairs[\"label\"].unique()).issubset({0, 1})\n",
    "assert df_pairs[\"pdb_id\"].str.len().eq(4).all()\n",
    "\n",
    "print(\"Interações (depois dedup):\", df_pairs.shape)\n",
    "print(\"PDBs únicos:\", df_pairs[\"pdb_id\"].nunique())\n",
    "print(df_pairs[\"label\"].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da97057",
   "metadata": {},
   "source": [
    "Passo 6 — Criar antibody_sequence e features simples (bioquímicas)\n",
    "\n",
    "estas features são ótimas para:\n",
    "\n",
    "baseline\n",
    "\n",
    "EDA\n",
    "\n",
    "justificar processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1918f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3994, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdb_id</th>\n",
       "      <th>chain_heavy</th>\n",
       "      <th>chain_light</th>\n",
       "      <th>variant_target</th>\n",
       "      <th>label</th>\n",
       "      <th>antibody_sequence</th>\n",
       "      <th>vh_len</th>\n",
       "      <th>vh_frac_gly</th>\n",
       "      <th>vh_frac_pro</th>\n",
       "      <th>vh_frac_aromatic</th>\n",
       "      <th>...</th>\n",
       "      <th>vl_len</th>\n",
       "      <th>vl_frac_gly</th>\n",
       "      <th>vl_frac_pro</th>\n",
       "      <th>vl_frac_aromatic</th>\n",
       "      <th>vl_frac_charged</th>\n",
       "      <th>ab_len</th>\n",
       "      <th>ab_frac_gly</th>\n",
       "      <th>ab_frac_pro</th>\n",
       "      <th>ab_frac_aromatic</th>\n",
       "      <th>ab_frac_charged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8J1T</td>\n",
       "      <td>VQLVESGGGLVQPGGSLRLSCAASGLTVSSNYMNWVRQAPGKGLEW...</td>\n",
       "      <td>DIQMTQSPSFLSASVGDRVTITCRASQGISSYLAWYQQKPGKAPKL...</td>\n",
       "      <td>SARS-CoV2_WT</td>\n",
       "      <td>1</td>\n",
       "      <td>VQLVESGGGLVQPGGSLRLSCAASGLTVSSNYMNWVRQAPGKGLEW...</td>\n",
       "      <td>115</td>\n",
       "      <td>0.121739</td>\n",
       "      <td>0.026087</td>\n",
       "      <td>0.104348</td>\n",
       "      <td>...</td>\n",
       "      <td>108</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.12037</td>\n",
       "      <td>0.12963</td>\n",
       "      <td>223</td>\n",
       "      <td>0.103139</td>\n",
       "      <td>0.040359</td>\n",
       "      <td>0.112108</td>\n",
       "      <td>0.147982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8J1T</td>\n",
       "      <td>VQLVESGGGLVQPGGSLRLSCAASGLTVSSNYMNWVRQAPGKGLEW...</td>\n",
       "      <td>DIQMTQSPSFLSASVGDRVTITCRASQGISSYLAWYQQKPGKAPKL...</td>\n",
       "      <td>SARS-CoV2_Alpha</td>\n",
       "      <td>1</td>\n",
       "      <td>VQLVESGGGLVQPGGSLRLSCAASGLTVSSNYMNWVRQAPGKGLEW...</td>\n",
       "      <td>115</td>\n",
       "      <td>0.121739</td>\n",
       "      <td>0.026087</td>\n",
       "      <td>0.104348</td>\n",
       "      <td>...</td>\n",
       "      <td>108</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.12037</td>\n",
       "      <td>0.12963</td>\n",
       "      <td>223</td>\n",
       "      <td>0.103139</td>\n",
       "      <td>0.040359</td>\n",
       "      <td>0.112108</td>\n",
       "      <td>0.147982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8J1T</td>\n",
       "      <td>VQLVESGGGLVQPGGSLRLSCAASGLTVSSNYMNWVRQAPGKGLEW...</td>\n",
       "      <td>DIQMTQSPSFLSASVGDRVTITCRASQGISSYLAWYQQKPGKAPKL...</td>\n",
       "      <td>SARS-CoV2_Beta</td>\n",
       "      <td>1</td>\n",
       "      <td>VQLVESGGGLVQPGGSLRLSCAASGLTVSSNYMNWVRQAPGKGLEW...</td>\n",
       "      <td>115</td>\n",
       "      <td>0.121739</td>\n",
       "      <td>0.026087</td>\n",
       "      <td>0.104348</td>\n",
       "      <td>...</td>\n",
       "      <td>108</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.12037</td>\n",
       "      <td>0.12963</td>\n",
       "      <td>223</td>\n",
       "      <td>0.103139</td>\n",
       "      <td>0.040359</td>\n",
       "      <td>0.112108</td>\n",
       "      <td>0.147982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  pdb_id                                        chain_heavy  \\\n",
       "0   8J1T  VQLVESGGGLVQPGGSLRLSCAASGLTVSSNYMNWVRQAPGKGLEW...   \n",
       "1   8J1T  VQLVESGGGLVQPGGSLRLSCAASGLTVSSNYMNWVRQAPGKGLEW...   \n",
       "2   8J1T  VQLVESGGGLVQPGGSLRLSCAASGLTVSSNYMNWVRQAPGKGLEW...   \n",
       "\n",
       "                                         chain_light   variant_target  label  \\\n",
       "0  DIQMTQSPSFLSASVGDRVTITCRASQGISSYLAWYQQKPGKAPKL...     SARS-CoV2_WT      1   \n",
       "1  DIQMTQSPSFLSASVGDRVTITCRASQGISSYLAWYQQKPGKAPKL...  SARS-CoV2_Alpha      1   \n",
       "2  DIQMTQSPSFLSASVGDRVTITCRASQGISSYLAWYQQKPGKAPKL...   SARS-CoV2_Beta      1   \n",
       "\n",
       "                                   antibody_sequence  vh_len  vh_frac_gly  \\\n",
       "0  VQLVESGGGLVQPGGSLRLSCAASGLTVSSNYMNWVRQAPGKGLEW...     115     0.121739   \n",
       "1  VQLVESGGGLVQPGGSLRLSCAASGLTVSSNYMNWVRQAPGKGLEW...     115     0.121739   \n",
       "2  VQLVESGGGLVQPGGSLRLSCAASGLTVSSNYMNWVRQAPGKGLEW...     115     0.121739   \n",
       "\n",
       "   vh_frac_pro  vh_frac_aromatic  ...  vl_len  vl_frac_gly  vl_frac_pro  \\\n",
       "0     0.026087          0.104348  ...     108     0.083333     0.055556   \n",
       "1     0.026087          0.104348  ...     108     0.083333     0.055556   \n",
       "2     0.026087          0.104348  ...     108     0.083333     0.055556   \n",
       "\n",
       "   vl_frac_aromatic  vl_frac_charged  ab_len  ab_frac_gly  ab_frac_pro  \\\n",
       "0           0.12037          0.12963     223     0.103139     0.040359   \n",
       "1           0.12037          0.12963     223     0.103139     0.040359   \n",
       "2           0.12037          0.12963     223     0.103139     0.040359   \n",
       "\n",
       "   ab_frac_aromatic  ab_frac_charged  \n",
       "0          0.112108         0.147982  \n",
       "1          0.112108         0.147982  \n",
       "2          0.112108         0.147982  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def aa_freq_features(seq: str, prefix: str) -> dict:\n",
    "    # frequência relativa de cada AA\n",
    "    n = len(seq)\n",
    "    counts = {aa: 0 for aa in AA_VALID}\n",
    "    for ch in seq:\n",
    "        counts[ch] += 1\n",
    "    return {f\"{prefix}_freq_{aa}\": counts[aa] / n for aa in sorted(AA_VALID)}\n",
    "\n",
    "def basic_seq_features(seq: str, prefix: str) -> dict:\n",
    "    return {\n",
    "        f\"{prefix}_len\": len(seq),\n",
    "        f\"{prefix}_frac_gly\": seq.count(\"G\") / len(seq),\n",
    "        f\"{prefix}_frac_pro\": seq.count(\"P\") / len(seq),\n",
    "        f\"{prefix}_frac_aromatic\": sum(seq.count(x) for x in [\"F\", \"W\", \"Y\"]) / len(seq),\n",
    "        f\"{prefix}_frac_charged\": sum(seq.count(x) for x in [\"D\",\"E\",\"K\",\"R\",\"H\"]) / len(seq),\n",
    "    }\n",
    "\n",
    "df_pairs[\"antibody_sequence\"] = df_pairs[\"chain_heavy\"] + df_pairs[\"chain_light\"]\n",
    "\n",
    "# construir features numéricas (opcional, mas recomendado)\n",
    "feat_rows = []\n",
    "for _, r in df_pairs.iterrows():\n",
    "    vh, vl, ab = r[\"chain_heavy\"], r[\"chain_light\"], r[\"antibody_sequence\"]\n",
    "    feats = {}\n",
    "    feats |= basic_seq_features(vh, \"vh\")\n",
    "    feats |= basic_seq_features(vl, \"vl\")\n",
    "    feats |= basic_seq_features(ab, \"ab\")\n",
    "    # (se quiseres muitas features: aa_freq_features também)\n",
    "    feat_rows.append(feats)\n",
    "\n",
    "df_feats = pd.DataFrame(feat_rows)\n",
    "df_final = pd.concat([df_pairs.reset_index(drop=True), df_feats.reset_index(drop=True)], axis=1)\n",
    "\n",
    "print(df_final.shape)\n",
    "df_final.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b941f9",
   "metadata": {},
   "source": [
    "Passo 7 — Preparar anti–data leakage (GroupKFold)\n",
    "\n",
    "A ideia é: o mesmo pdb_id nunca pode estar em treino e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "248eaf41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  pdb_id\n",
      "0   8J1T\n",
      "1   8J1T\n",
      "2   8J1T\n",
      "3   8J1T\n",
      "4   8J1T\n"
     ]
    }
   ],
   "source": [
    "# isto é o \"grupo\" para GroupKFold\n",
    "groups = df_final[\"pdb_id\"].copy()\n",
    "\n",
    "# quick check: tamanho consistente\n",
    "assert len(groups) == len(df_final)\n",
    "\n",
    "# guardar ficheiro auxiliar\n",
    "df_groups = pd.DataFrame({\"pdb_id\": df_final[\"pdb_id\"]})\n",
    "df_groups.to_csv(\"groups_pdb.csv\", index=False)\n",
    "\n",
    "print(df_groups.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c925cf",
   "metadata": {},
   "source": [
    "Passo 8 — Guardar outputs finais desta fase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6a92719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado:\n",
      "- dataset_molecular_clean.csv\n",
      "- groups_pdb.csv\n"
     ]
    }
   ],
   "source": [
    "df_final.to_csv(\"dataset_molecular_clean.csv\", index=False)\n",
    "\n",
    "print(\"Guardado:\")\n",
    "print(\"- dataset_molecular_clean.csv\")\n",
    "print(\"- groups_pdb.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871a0c55",
   "metadata": {},
   "source": [
    "Passo 9 - Integração com PDBs para GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "311e5f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDBs no ZIP: 988\n",
      "PDBs alvo (do dataset/lista): 472\n",
      "\n",
      "Done ✅\n",
      "Processed: 413\n",
      "Skipped (already done): 16\n",
      "Missing in ZIP: 43\n",
      "Failed: 0\n",
      "Outputs in: C:\\Users\\filip\\OneDrive\\Documents\\Universidade\\mestrado\\ano_2\\1_semestre\\SIB\\Trabalho_grupo\\graphs_npz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "from typing import Optional, Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# -------------------------\n",
    "# Config\n",
    "# -------------------------\n",
    "DATASET_CSV = Path(\"dataset_molecular_clean.csv\")\n",
    "ZIP_PATH = Path(\"Structures_pdbs.zip\")   # <- o teu ficheiro\n",
    "OUT_DIR = Path(\"graphs_npz\")\n",
    "\n",
    "# Se tiveres uma lista fixa de PDBs (ex: 472), podes ligar isto depois:\n",
    "PDB_LIST_CSV: Optional[Path] = None  # ex: Path(\"pdb_all_472.csv\")\n",
    "\n",
    "CUTOFF = 8.0\n",
    "RESUME = True\n",
    "MAX_CA = None  # ex: 2000 se quiseres limitar estruturas muito grandes\n",
    "\n",
    "PDB_ID_RE = re.compile(r\"([0-9][a-z0-9]{3})\", re.IGNORECASE)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Helpers\n",
    "# -------------------------\n",
    "def infer_pdb_id_from_name(name: str) -> Optional[str]:\n",
    "    base = Path(name).name\n",
    "    m = PDB_ID_RE.search(base)\n",
    "    return m.group(1).upper() if m else None\n",
    "\n",
    "\n",
    "\n",
    "def ensure_dir(p: Path) -> None:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def load_target_pdb_ids(dataset_csv: Path, pdb_list_csv: Optional[Path] = None) -> List[str]:\n",
    "    df = pd.read_csv(dataset_csv)\n",
    "    if \"pdb_id\" not in df.columns:\n",
    "        raise ValueError(\"dataset_molecular_clean.csv tem de ter coluna 'pdb_id'.\")\n",
    "\n",
    "    if pdb_list_csv and pdb_list_csv.exists():\n",
    "        s = pd.read_csv(pdb_list_csv)[\"pdb_id\"].astype(str).str.upper()\n",
    "        return sorted(set(s.tolist()))\n",
    "\n",
    "    return sorted(df[\"pdb_id\"].astype(str).str.upper().unique().tolist())\n",
    "\n",
    "\n",
    "def parse_pdb_ca_coords_from_lines(lines: List[str]) -> np.ndarray:\n",
    "    coords = []\n",
    "    for line in lines:\n",
    "        if not line.startswith(\"ATOM\"):\n",
    "            continue\n",
    "        atom_name = line[12:16].strip()\n",
    "        if atom_name != \"CA\":\n",
    "            continue\n",
    "        try:\n",
    "            x = float(line[30:38])\n",
    "            y = float(line[38:46])\n",
    "            z = float(line[46:54])\n",
    "        except ValueError:\n",
    "            continue\n",
    "        coords.append((x, y, z))\n",
    "\n",
    "    if not coords:\n",
    "        return np.zeros((0, 3), dtype=np.float32)\n",
    "    return np.asarray(coords, dtype=np.float32)\n",
    "\n",
    "\n",
    "def build_radius_graph(coords: np.ndarray, cutoff: float = 8.0) -> np.ndarray:\n",
    "    n = coords.shape[0]\n",
    "    if n == 0:\n",
    "        return np.zeros((2, 0), dtype=np.int64)\n",
    "\n",
    "    diff = coords[:, None, :] - coords[None, :, :]\n",
    "    d2 = np.einsum(\"ijk,ijk->ij\", diff, diff)\n",
    "    mask = (d2 <= cutoff * cutoff) & (d2 > 0.0)\n",
    "\n",
    "    src, dst = np.where(mask)\n",
    "    return np.stack([src, dst], axis=0).astype(np.int64)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# ZIP source\n",
    "# -------------------------\n",
    "class ZipPDBSource:\n",
    "    def __init__(self, zip_path: Path):\n",
    "        self.zip_path = zip_path\n",
    "        self.zf = zipfile.ZipFile(zip_path, \"r\")\n",
    "\n",
    "    def iter_available(self) -> Dict[str, str]:\n",
    "        out = {}\n",
    "        for name in self.zf.namelist():\n",
    "            if name.endswith(\"/\"):\n",
    "                continue\n",
    "            if not name.lower().endswith(\".pdb\"):\n",
    "                continue\n",
    "\n",
    "            pid = infer_pdb_id_from_name(Path(name).name) or infer_pdb_id_from_name(name)\n",
    "            if pid:\n",
    "                out[pid] = name\n",
    "        return out\n",
    "\n",
    "    def read_pdb_lines(self, internal_ref: str) -> List[str]:\n",
    "        with self.zf.open(internal_ref, \"r\") as f:\n",
    "            content = f.read().decode(\"utf-8\", errors=\"ignore\")\n",
    "        return content.splitlines(True)\n",
    "\n",
    "    def close(self):\n",
    "        self.zf.close()\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Main\n",
    "# -------------------------\n",
    "def build_graphs():\n",
    "    if not DATASET_CSV.exists():\n",
    "        raise FileNotFoundError(f\"Não encontrei {DATASET_CSV} no diretório atual.\")\n",
    "\n",
    "    if not ZIP_PATH.exists():\n",
    "        raise FileNotFoundError(f\"Não encontrei {ZIP_PATH} no diretório atual.\")\n",
    "\n",
    "    ensure_dir(OUT_DIR)\n",
    "\n",
    "    log_path = OUT_DIR / \"pdb_processing_log.txt\"\n",
    "    report_path = OUT_DIR / \"pdb_processing_report.csv\"\n",
    "\n",
    "    target_pdbs = load_target_pdb_ids(DATASET_CSV, PDB_LIST_CSV)\n",
    "\n",
    "    src = ZipPDBSource(ZIP_PATH)\n",
    "    try:\n",
    "        available = src.iter_available()\n",
    "        print(f\"PDBs no ZIP: {len(available)}\")\n",
    "        print(f\"PDBs alvo (do dataset/lista): {len(target_pdbs)}\")\n",
    "\n",
    "        # cria report se não existir\n",
    "        if not report_path.exists():\n",
    "            with open(report_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "                w = csv.writer(f)\n",
    "                w.writerow([\"pdb_id\", \"status\", \"n_nodes\", \"n_edges\", \"message\"])\n",
    "\n",
    "        def already_done(pdb_id: str) -> bool:\n",
    "            return (OUT_DIR / f\"{pdb_id}.npz\").exists()\n",
    "\n",
    "        processed = skipped = missing = failed = 0\n",
    "\n",
    "        with open(log_path, \"a\", encoding=\"utf-8\") as logf, open(report_path, \"a\", newline=\"\", encoding=\"utf-8\") as repf:\n",
    "            repw = csv.writer(repf)\n",
    "\n",
    "            for pdb_id in target_pdbs:\n",
    "                if RESUME and already_done(pdb_id):\n",
    "                    skipped += 1\n",
    "                    continue\n",
    "\n",
    "                if pdb_id not in available:\n",
    "                    missing += 1\n",
    "                    repw.writerow([pdb_id, \"missing\", \"\", \"\", \"PDB not found in ZIP\"])\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    lines = src.read_pdb_lines(available[pdb_id])\n",
    "                    coords = parse_pdb_ca_coords_from_lines(lines)\n",
    "\n",
    "                    if coords.shape[0] == 0:\n",
    "                        repw.writerow([pdb_id, \"no_ca\", 0, 0, \"No CA atoms found\"])\n",
    "                        continue\n",
    "\n",
    "                    if MAX_CA is not None and coords.shape[0] > MAX_CA:\n",
    "                        coords = coords[:MAX_CA, :]\n",
    "\n",
    "                    edge_index = build_radius_graph(coords, cutoff=CUTOFF)\n",
    "\n",
    "                    np.savez_compressed(\n",
    "                        OUT_DIR / f\"{pdb_id}.npz\",\n",
    "                        coords=coords.astype(np.float32),\n",
    "                        edge_index=edge_index.astype(np.int64),\n",
    "                        cutoff=np.array([CUTOFF], dtype=np.float32),\n",
    "                    )\n",
    "\n",
    "                    repw.writerow([pdb_id, \"ok\", coords.shape[0], edge_index.shape[1], \"\"])\n",
    "                    processed += 1\n",
    "\n",
    "                    if processed % 25 == 0:\n",
    "                        logf.write(f\"[OK] processed {processed} graphs so far...\\n\")\n",
    "                        logf.flush()\n",
    "\n",
    "                except Exception as e:\n",
    "                    failed += 1\n",
    "                    msg = f\"{type(e).__name__}: {e}\"\n",
    "                    repw.writerow([pdb_id, \"error\", \"\", \"\", msg])\n",
    "                    logf.write(f\"[ERROR] {pdb_id} -> {msg}\\n\")\n",
    "                    logf.flush()\n",
    "\n",
    "        print(\"\\nDone ✅\")\n",
    "        print(f\"Processed: {processed}\")\n",
    "        print(f\"Skipped (already done): {skipped}\")\n",
    "        print(f\"Missing in ZIP: {missing}\")\n",
    "        print(f\"Failed: {failed}\")\n",
    "        print(f\"Outputs in: {OUT_DIR.resolve()}\")\n",
    "\n",
    "    finally:\n",
    "        src.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    build_graphs()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ea664e",
   "metadata": {},
   "source": [
    "Passo 10 - Criação de Dataset final com PDBs com grafos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "123aebdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset IN: (3994, 21) | PDBs únicos: 472\n",
      "OK por .npz: 429\n",
      "OK finais (usáveis): 429\n",
      "Dataset GNN-ready: (3760, 21) | PDBs únicos: 429\n",
      "\n",
      "Guardado:\n",
      "- dataset_molecular_gnn_ready.csv\n",
      "- groups_pdb_gnn_ready.csv\n",
      "- pdbs_dropped_no_graph.csv (para registo)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- Paths (ajusta se precisares)\n",
    "DATASET_IN = Path(\"dataset_molecular_clean.csv\")\n",
    "REPORT_CSV = Path(\"pdb_processing_report.csv\")        # o teu report anexado/gerado\n",
    "GRAPHS_DIR = Path(\"graphs_npz\")                       # onde estão os .npz\n",
    "OUT_DATASET = Path(\"dataset_molecular_gnn_ready.csv\")\n",
    "OUT_GROUPS  = Path(\"groups_pdb_gnn_ready.csv\")\n",
    "\n",
    "# --- 1) Carregar dataset\n",
    "df = pd.read_csv(DATASET_IN)\n",
    "df[\"pdb_id\"] = df[\"pdb_id\"].astype(str).str.upper()\n",
    "\n",
    "print(\"Dataset IN:\", df.shape, \"| PDBs únicos:\", df[\"pdb_id\"].nunique())\n",
    "\n",
    "# --- 2) Ler report e obter PDBs com status ok (se o report existir)\n",
    "ok_from_report = set()\n",
    "missing_from_report = set()\n",
    "if REPORT_CSV.exists():\n",
    "    df_report = pd.read_csv(REPORT_CSV)\n",
    "    for _, row in df_report.iterrows():\n",
    "        pid = str(row[\"pdb_id\"]).upper()\n",
    "        status = str(row[\"status\"]).lower()\n",
    "        if status == \"ok\":\n",
    "            ok_from_report.add(pid)\n",
    "        else:\n",
    "            missing_from_report.add(pid)\n",
    "\n",
    "    print(\"OK por report:\", len(ok_from_report))\n",
    "    print(\"Missing/failed por report:\", len(missing_from_report))\n",
    "    \n",
    "# --- 3) Confirmar via filesystem (fonte de verdade): PDBs com .npz em graphs_npz\n",
    "ok_from_npz = set(p.stem.upper() for p in GRAPHS_DIR.glob(\"*.npz\"))\n",
    "print(\"OK por .npz:\", len(ok_from_npz))\n",
    "\n",
    "# --- 4) PDBs finais utilizáveis (interseção ajuda a evitar falsos positivos)\n",
    "# Se tiveres report e npz, usa a interseção; se não, usa npz.\n",
    "if ok_from_report:\n",
    "    ok_pdbs = ok_from_report.intersection(ok_from_npz)\n",
    "else:\n",
    "    ok_pdbs = ok_from_npz\n",
    "\n",
    "print(\"OK finais (usáveis):\", len(ok_pdbs))\n",
    "\n",
    "# --- 5) Filtrar dataset para apenas PDBs com grafo\n",
    "df_gnn = df[df[\"pdb_id\"].isin(ok_pdbs)].copy()\n",
    "\n",
    "print(\"Dataset GNN-ready:\", df_gnn.shape, \"| PDBs únicos:\", df_gnn[\"pdb_id\"].nunique())\n",
    "\n",
    "# --- 6) Guardar outputs finais\n",
    "df_gnn.to_csv(OUT_DATASET, index=False)\n",
    "pd.DataFrame({\"pdb_id\": df_gnn[\"pdb_id\"]}).to_csv(OUT_GROUPS, index=False)\n",
    "\n",
    "print(\"\\nGuardado:\")\n",
    "print(\"-\", OUT_DATASET)\n",
    "print(\"-\", OUT_GROUPS)\n",
    "\n",
    "# --- 7) (opcional) lista de PDBs que ficaram de fora (útil para documentação)\n",
    "pdbs_all = set(df[\"pdb_id\"].unique())\n",
    "pdbs_dropped = sorted(pdbs_all - set(df_gnn[\"pdb_id\"].unique()))\n",
    "pd.Series(pdbs_dropped, name=\"pdb_id_dropped\").to_csv(\"pdbs_dropped_no_graph.csv\", index=False)\n",
    "print(\"- pdbs_dropped_no_graph.csv (para registo)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
