{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-04T23:18:26.146430Z",
     "start_time": "2026-01-04T23:18:12.950229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.nn import GATv2Conv, global_mean_pool, global_max_pool\n",
    "\n",
    "# --- CONFIGURAÇÃO ---\n",
    "# Aponta para a pasta onde geraste os .npz no passo anterior\n",
    "GRAPHS_DIR = 'graphs_npz'\n",
    "DATASET_CSV = 'dataset_molecular_gnn_ready.csv'\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.0005\n",
    "EPOCHS = 25\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"Configuração definida. A usar device: {DEVICE}\")"
   ],
   "id": "a51f5f96c60c326e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuração definida. A usar device: cpu\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-04T23:22:30.451618Z",
     "start_time": "2026-01-04T23:22:30.432429Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class AntibodyGraphDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # Mapeamento de Aminoácidos para Inteiros (para reconstruir features se faltarem no npz)\n",
    "        self.aa_map = {k: v for v, k in enumerate(\"ACDEFGHIKLMNPQRSTVWY\")}\n",
    "        self.aa_map['X'] = 20 # Desconhecido\n",
    "\n",
    "        # Preparar Encoder de Variantes\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.df['variant_encoded'] = self.label_encoder.fit_transform(self.df['variant_target'])\n",
    "        self.num_variants = len(self.label_encoder.classes_)\n",
    "\n",
    "        print(f\"Dataset inicializado. {len(self.df)} amostras.\")\n",
    "        print(f\"Variantes únicas: {self.num_variants}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 1. Identificar o ficheiro\n",
    "        row = self.df.iloc[idx]\n",
    "        pdb_id = str(row['pdb_id'])\n",
    "        npz_path = os.path.join(self.root_dir, f\"{pdb_id}.npz\")\n",
    "\n",
    "        # 2. Carregar o NPZ\n",
    "        if not os.path.exists(npz_path):\n",
    "            # Fallback seguro se faltar ficheiro (evita crashar treino)\n",
    "            return self.__getitem__((idx + 1) % len(self.df))\n",
    "\n",
    "        try:\n",
    "            data_npz = np.load(npz_path)\n",
    "\n",
    "            # 3. Construir Tensores\n",
    "            # Coordenadas\n",
    "            pos = torch.from_numpy(data_npz['coords']).float()\n",
    "\n",
    "            # Arestas\n",
    "            edge_index = torch.from_numpy(data_npz['edge_index']).long()\n",
    "\n",
    "            # Features dos Nós (x)\n",
    "            # Tenta carregar do NPZ, se não existir, reconstrói da sequência no CSV\n",
    "            if 'x' in data_npz:\n",
    "                x = torch.from_numpy(data_npz['x']).long()\n",
    "            else:\n",
    "                x = self._reconstruct_node_features(row, len(pos))\n",
    "\n",
    "            # Labels e Variante\n",
    "            y = torch.tensor([row['label']], dtype=torch.float)\n",
    "            variant_id = torch.tensor([row['variant_encoded']], dtype=torch.long)\n",
    "\n",
    "            # Objeto Data PyG\n",
    "            data = Data(x=x, edge_index=edge_index, pos=pos, y=y)\n",
    "            data.variant_id = variant_id # Anexar ID da variante\n",
    "\n",
    "            return data\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao carregar {pdb_id}: {e}\")\n",
    "            return self.__getitem__((idx + 1) % len(self.df))\n",
    "\n",
    "    def _reconstruct_node_features(self, row, num_nodes_graph):\n",
    "        \"\"\"\n",
    "        Reconstrói features dos nós a partir da sequência de texto (H + L)\n",
    "        se elas não estiverem no ficheiro .npz.\n",
    "        \"\"\"\n",
    "        # Concatena cadeias H e L (assumindo que foi esta a ordem de extração)\n",
    "        full_seq = (str(row['chain_heavy']) + str(row['chain_light'])).upper()\n",
    "\n",
    "        # Se os tamanhos não baterem certo (comum em PDBs com resíduos em falta),\n",
    "        # criamos features dummy para não crashar, mas idealmente corrigia-se o pré-processamento.\n",
    "        if len(full_seq) != num_nodes_graph:\n",
    "            # Fallback: features aleatórias ou zeros (apenas para não parar o código)\n",
    "            # Num cenário real, deve-se garantir a consistência no passo anterior.\n",
    "            indices = [0] * num_nodes_graph\n",
    "        else:\n",
    "            indices = [self.aa_map.get(aa, 20) for aa in full_seq]\n",
    "\n",
    "        return torch.tensor(indices, dtype=torch.long).unsqueeze(1)"
   ],
   "id": "b1d49cadac9ca640",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-04T23:22:34.643318Z",
     "start_time": "2026-01-04T23:22:34.621637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class HybridNeutralizationModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Arquitetura Híbrida (GNN + Semântica) atualizada para o Módulo 1.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_node_features=1, num_variants=10, embedding_dim=64, hidden_dim=128):\n",
    "        super(HybridNeutralizationModel, self).__init__()\n",
    "\n",
    "        # --- GNN (Estrutura) ---\n",
    "        self.node_embedding = nn.Embedding(21, hidden_dim) # 20 aminoácidos + 1 desconhecido\n",
    "\n",
    "        self.conv1 = GATv2Conv(hidden_dim, hidden_dim, heads=4, concat=True, dropout=0.1)\n",
    "        self.conv2 = GATv2Conv(hidden_dim * 4, hidden_dim, heads=1, concat=False, dropout=0.1)\n",
    "\n",
    "        # --- NLP (Variante) ---\n",
    "        self.variant_embedding = nn.Embedding(num_embeddings=num_variants, embedding_dim=hidden_dim)\n",
    "\n",
    "        # --- Fusão ---\n",
    "        self.fusion_dim = hidden_dim * 2\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.fusion_dim, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, data, variant_ids):\n",
    "        # 1. GNN\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        # Garantir que x é LongTensor para o Embedding\n",
    "        x = x.long()\n",
    "        if x.dim() > 1: x = x.squeeze()\n",
    "\n",
    "        x = self.node_embedding(x)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "\n",
    "        # Global Pooling (Nós -> Grafo)\n",
    "        x_graph = global_mean_pool(x, batch) + global_max_pool(x, batch)\n",
    "\n",
    "        # 2. Variante\n",
    "        x_variant = self.variant_embedding(variant_ids)\n",
    "\n",
    "        # 3. Fusão\n",
    "        combined = torch.cat([x_graph, x_variant], dim=1)\n",
    "\n",
    "        # 4. Classificação\n",
    "        logits = self.classifier(combined)\n",
    "        return logits"
   ],
   "id": "67728f1bf895cbd0",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Especificação Técnica da Arquitetura de Modelação (Módulo 1)\n",
    "\n",
    "## 1. Definição Formal do Modelo\n",
    "\n",
    "O modelo desenvolvido é classificado como uma **Rede Neuronal Híbrida Multi-Modal (*Multi-Modal Hybrid Neural Network*)**.\n",
    "\n",
    "A sua função matemática, , procura aproximar a probabilidade condicional de neutralização , dados dois inputs heterogéneos: a estrutura topológica do anticorpo () e a identidade semântica da variante viral ().\n",
    "\n",
    "Onde:\n",
    "\n",
    "*  é o grafo molecular do anticorpo.\n",
    "*  é o identificador categórico da variante.\n",
    "*  representa os parâmetros treináveis da rede.\n",
    "*  é a função de ativação Sigmóide que mapeia o output para o intervalo .\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Decomposição da Arquitetura\n",
    "\n",
    "A rede está estruturada em três blocos funcionais sequenciais:\n",
    "\n",
    "### Bloco A: Codificador Estrutural (The Structural Encoder)\n",
    "\n",
    "**Objetivo:** Transformar a estrutura 3D complexa e esparsa do anticorpo num vetor de características latentes de dimensão fixa.\n",
    "\n",
    "* **Representação de Entrada (Input):** O anticorpo não é tratado como uma imagem (grid Euclidiana), mas sim como um **Grafo Geométrico não-Euclidiano**.\n",
    "* **Nós ():** Cada nó representa um resíduo de aminoácido (Cadeias Pesada e Leve).\n",
    "* **Arestas ():** Definidas por um *cutoff* de distância espacial (< 10 Ångströms) entre Carbonos-Alfa (). Isto captura as interações não-covalentes e a geometria de dobragem da proteína.\n",
    "* **Features dos Nós:** Inicialmente, cada nó possui apenas um índice inteiro representando o seu tipo de aminoácido (0-20). Uma camada de *Embedding* () projeta este índice num espaço vetorial denso (), permitindo à rede aprender propriedades físico-químicas (ex: hidrofobicidade, carga) de forma autónoma.\n",
    "\n",
    "\n",
    "* **Mecanismo de Processamento: Graph Attention Networks (GATv2):**\n",
    "Em vez de convoluções em grafos padrão (GCN), utilizamos a arquitetura **GATv2**.\n",
    "* *Justificação Teórica:* Numa interação anticorpo-antigénio, nem todos os resíduos são iguais. Apenas os resíduos nas regiões CDR (*Complementarity-Determining Regions*) interagem diretamente com o vírus.\n",
    "* *Mecanismo:* A GATv2 aplica um **Mecanismo de Atenção (*Self-Attention*)**. Para cada nó, a rede calcula uma pontuação de importância para os seus vizinhos. Isto permite ao modelo \"aprender a olhar\" preferencialmente para as regiões estruturais críticas para a ligação, ignorando o \"ruído\" do esqueleto proteico conservado.\n",
    "\n",
    "\n",
    "* **Agregação (Global Pooling):**\n",
    "Após as camadas convolucionais, o grafo de  nós precisa de ser reduzido a um único vetor que represente a molécula inteira. Utilizamos uma estratégia híbrida:\n",
    "\n",
    "\n",
    "\n",
    "Isto captura tanto a composição média do anticorpo como a presença de características locais fortes (motivos estruturais específicos).\n",
    "\n",
    "### Bloco B: Codificador Semântico (The Semantic Encoder)\n",
    "\n",
    "**Objetivo:** Injetar o contexto biológico da variante viral alvo.\n",
    "\n",
    "* **O Problema dos Dados:** Como o dataset de treino possui apenas a identificação nominal das variantes (ex: \"Omicron\", \"Delta\") e não as suas estruturas 3D complexadas, a estrutura viral não pode ser inserida na GNN.\n",
    "* **A Solução (Learned Embeddings):**\n",
    "Utilizamos uma camada de *Embedding* que mapeia cada ID de variante () para um vetor denso ().\n",
    "* Durante o processo de *Backpropagation*, a rede ajusta os valores deste vetor.\n",
    "* **Interpretação:** Variantes que são neutralizadas pelos mesmos anticorpos acabarão por ter representações vetoriais matematicamente próximas neste espaço latente (\"Clusterização Funcional\").\n",
    "Justificação da Escolha:\n",
    "* **Roadmap Futuro**: Para a versão final, planeamos enriquecer o dataset com sequências externas (NCBI) para substituir este módulo por um processador de sequências (ProtBERT), permitindo generalização total.\n",
    "\n",
    "\n",
    "\n",
    "### Bloco C: Módulo de Fusão e Classificação (Fusion & MLP Head)\n",
    "\n",
    "**Objetivo:** Correlacionar a estrutura do anticorpo com a identidade do vírus para prever o fenótipo.\n",
    "\n",
    "* **Fusão Multi-Modal:** Os vetores latentes do anticorpo () e da variante () são concatenados, criando um vetor único que representa o **par biológico**.\n",
    "\n",
    "\n",
    "* **Perceptrão Multicamada (MLP):**\n",
    "O vetor combinado atravessa camadas densas (*Linear Layers*) que aprendem as relações não-lineares complexas entre a forma do anticorpo e o tipo de vírus.\n",
    "* **Regularização e Estabilidade:**\n",
    "* **Batch Normalization:** Normaliza os outputs de cada camada intermédia para estabilizar e acelerar o treino.\n",
    "* **Dropout (0.3):** Desativa aleatoriamente 30% dos neurónios durante o treino. Isto introduz ruído estocástico que previne o modelo de \"memorizar\" exemplos específicos (*Overfitting*), forçando-o a aprender padrões generalizáveis.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Fluxo de Aprendizagem (Training Dynamics)\n",
    "\n",
    "Embora a classe `HybridNeutralizationModel` defina a estrutura (o \"corpo\"), a inteligência surge através do processo de otimização:\n",
    "\n",
    "1. **Forward Pass (Inferência):** Os dados fluem da entrada para a saída, gerando uma previsão .\n",
    "2. **Cálculo de Perda (Loss Function):** Utilizamos a **Entropia Cruzada Binária com Logits (*BCEWithLogitsLoss*)**. Esta função mede a distância matemática entre a previsão do modelo e a realidade biológica (0 ou 1).\n",
    "3. **Backward Pass (Retropropagação):** O algoritmo de *Backpropagation* calcula o gradiente do erro em relação a cada um dos ~315.000 parâmetros da rede.\n",
    "4. **Otimização (Adam):** O otimizador atualiza os pesos na direção oposta ao gradiente para minimizar o erro na próxima iteração.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Resumo das Inovações (Módulo 1)\n",
    "\n",
    "Esta arquitetura cumpre os requisitos de inovação do projeto através de:\n",
    "\n",
    "1. **Deep Learning Geométrico:** Abandono de descritores lineares clássicos em favor de representações baseadas em grafos que preservam a topologia 3D nativa.\n",
    "2. **Mecanismos de Atenção:** Uso de GATv2 para mimetizar o foco biológico nas regiões de interação."
   ],
   "id": "3afe1c584bf593a0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
